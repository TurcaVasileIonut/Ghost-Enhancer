{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-06T09:25:44.760765Z",
     "start_time": "2024-05-06T09:25:44.586555Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# https://github.com/jaxony/ShuffleNet/blob/master/model.py\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "from collections import OrderedDict\n",
    "from torch.nn import init\n",
    "\n",
    "\n",
    "def conv3x3(in_channels, out_channels, stride=1, \n",
    "            padding=1, bias=True, groups=1):    \n",
    "    \"\"\"3x3 convolution with padding\n",
    "    \"\"\"\n",
    "    return nn.Conv2d(\n",
    "        in_channels, \n",
    "        out_channels, \n",
    "        kernel_size=3, \n",
    "        stride=stride,\n",
    "        padding=padding,\n",
    "        bias=bias,\n",
    "        groups=groups)\n",
    "\n",
    "\n",
    "def conv1x1(in_channels, out_channels, groups=1):\n",
    "    \"\"\"1x1 convolution with padding\n",
    "    - Normal pointwise convolution When groups == 1\n",
    "    - Grouped pointwise convolution when groups > 1\n",
    "    \"\"\"\n",
    "    return nn.Conv2d(\n",
    "        in_channels, \n",
    "        out_channels, \n",
    "        kernel_size=1, \n",
    "        groups=groups,\n",
    "        stride=1)\n",
    "\n",
    "\n",
    "def channel_shuffle(x, groups):\n",
    "    batchsize, num_channels, height, width = x.data.size()\n",
    "\n",
    "    channels_per_group = num_channels // groups\n",
    "    \n",
    "    # reshape\n",
    "    x = x.view(batchsize, groups, \n",
    "        channels_per_group, height, width)\n",
    "\n",
    "    # transpose\n",
    "    # - contiguous() required if transpose() is used before view().\n",
    "    #   See https://github.com/pytorch/pytorch/issues/764\n",
    "    x = torch.transpose(x, 1, 2).contiguous()\n",
    "\n",
    "    # flatten\n",
    "    x = x.view(batchsize, -1, height, width)\n",
    "\n",
    "    return x\n",
    "\n",
    "\n",
    "class ShuffleUnit(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, groups=3,\n",
    "                 grouped_conv=True, combine='add'):\n",
    "        \n",
    "        super(ShuffleUnit, self).__init__()\n",
    "\n",
    "        self.in_channels = in_channels\n",
    "        self.out_channels = out_channels\n",
    "        self.grouped_conv = grouped_conv\n",
    "        self.combine = combine\n",
    "        self.groups = groups\n",
    "        self.bottleneck_channels = self.out_channels // 4\n",
    "\n",
    "        # define the type of ShuffleUnit\n",
    "        if self.combine == 'add':\n",
    "            # ShuffleUnit Figure 2b\n",
    "            self.depthwise_stride = 1\n",
    "            self._combine_func = self._add\n",
    "        elif self.combine == 'concat':\n",
    "            # ShuffleUnit Figure 2c\n",
    "            self.depthwise_stride = 2\n",
    "            self._combine_func = self._concat\n",
    "            \n",
    "            # ensure output of concat has the same channels as \n",
    "            # original output channels.\n",
    "            self.out_channels -= self.in_channels\n",
    "        else:\n",
    "            raise ValueError(\"Cannot combine tensors with \\\"{}\\\"\" \\\n",
    "                             \"Only \\\"add\\\" and \\\"concat\\\" are\" \\\n",
    "                             \"supported\".format(self.combine))\n",
    "\n",
    "        # Use a 1x1 grouped or non-grouped convolution to reduce input channels\n",
    "        # to bottleneck channels, as in a ResNet bottleneck module.\n",
    "        # NOTE: Do not use group convolution for the first conv1x1 in Stage 2.\n",
    "        self.first_1x1_groups = self.groups if grouped_conv else 1\n",
    "\n",
    "        self.g_conv_1x1_compress = self._make_grouped_conv1x1(\n",
    "            self.in_channels,\n",
    "            self.bottleneck_channels,\n",
    "            self.first_1x1_groups,\n",
    "            batch_norm=True,\n",
    "            relu=True\n",
    "            )\n",
    "\n",
    "        # 3x3 depthwise convolution followed by batch normalization\n",
    "        self.depthwise_conv3x3 = conv3x3(\n",
    "            self.bottleneck_channels, self.bottleneck_channels,\n",
    "            stride=self.depthwise_stride, groups=self.bottleneck_channels)\n",
    "        self.bn_after_depthwise = nn.BatchNorm2d(self.bottleneck_channels)\n",
    "\n",
    "        # Use 1x1 grouped convolution to expand from \n",
    "        # bottleneck_channels to out_channels\n",
    "        self.g_conv_1x1_expand = self._make_grouped_conv1x1(\n",
    "            self.bottleneck_channels,\n",
    "            self.out_channels,\n",
    "            self.groups,\n",
    "            batch_norm=True,\n",
    "            relu=False\n",
    "            )\n",
    "\n",
    "\n",
    "    @staticmethod\n",
    "    def _add(x, out):\n",
    "        # residual connection\n",
    "        return x + out\n",
    "\n",
    "\n",
    "    @staticmethod\n",
    "    def _concat(x, out):\n",
    "        # concatenate along channel axis\n",
    "        return torch.cat((x, out), 1)\n",
    "\n",
    "\n",
    "    def _make_grouped_conv1x1(self, in_channels, out_channels, groups,\n",
    "        batch_norm=True, relu=False):\n",
    "\n",
    "        modules = OrderedDict()\n",
    "\n",
    "        conv = conv1x1(in_channels, out_channels, groups=groups)\n",
    "        modules['conv1x1'] = conv\n",
    "\n",
    "        if batch_norm:\n",
    "            modules['batch_norm'] = nn.BatchNorm2d(out_channels)\n",
    "        if relu:\n",
    "            modules['relu'] = nn.ReLU()\n",
    "        if len(modules) > 1:\n",
    "            return nn.Sequential(modules)\n",
    "        else:\n",
    "            return conv\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        # save for combining later with output\n",
    "        residual = x\n",
    "\n",
    "        if self.combine == 'concat':\n",
    "            residual = F.avg_pool2d(residual, kernel_size=3, \n",
    "                stride=2, padding=1)\n",
    "\n",
    "        out = self.g_conv_1x1_compress(x)\n",
    "        out = channel_shuffle(out, self.groups)\n",
    "        out = self.depthwise_conv3x3(out)\n",
    "        out = self.bn_after_depthwise(out)\n",
    "        out = self.g_conv_1x1_expand(out)\n",
    "        \n",
    "        out = self._combine_func(residual, out)\n",
    "        return F.relu(out)\n",
    "\n",
    "\n",
    "class ShuffleNet(nn.Module):\n",
    "    \"\"\"ShuffleNet implementation.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, groups=3, in_channels=3, num_classes=1000):\n",
    "        \"\"\"ShuffleNet constructor.\n",
    "\n",
    "        Arguments:\n",
    "            groups (int, optional): number of groups to be used in grouped \n",
    "                1x1 convolutions in each ShuffleUnit. Default is 3 for best\n",
    "                performance according to original paper.\n",
    "            in_channels (int, optional): number of channels in the input tensor.\n",
    "                Default is 3 for RGB image inputs.\n",
    "            num_classes (int, optional): number of classes to predict. Default\n",
    "                is 1000 for ImageNet.\n",
    "\n",
    "        \"\"\"\n",
    "        super(ShuffleNet, self).__init__()\n",
    "\n",
    "        self.groups = groups\n",
    "        self.stage_repeats = [3, 7, 3]\n",
    "        self.in_channels =  in_channels\n",
    "        self.num_classes = num_classes\n",
    "\n",
    "        # index 0 is invalid and should never be called.\n",
    "        # only used for indexing convenience.\n",
    "        if groups == 1:\n",
    "            self.stage_out_channels = [-1, 24, 144, 288, 567]\n",
    "        elif groups == 2:\n",
    "            self.stage_out_channels = [-1, 24, 200, 400, 800]\n",
    "        elif groups == 3:\n",
    "            self.stage_out_channels = [-1, 24, 240, 480, 960]\n",
    "        elif groups == 4:\n",
    "            self.stage_out_channels = [-1, 24, 272, 544, 1088]\n",
    "        elif groups == 8:\n",
    "            self.stage_out_channels = [-1, 24, 384, 768, 1536]\n",
    "        else:\n",
    "            raise ValueError(\n",
    "                \"\"\"{} groups is not supported for\n",
    "                   1x1 Grouped Convolutions\"\"\".format(num_groups))\n",
    "        \n",
    "        # Stage 1 always has 24 output channels\n",
    "        self.conv1 = conv3x3(self.in_channels,\n",
    "                             self.stage_out_channels[1], # stage 1\n",
    "                             stride=2)\n",
    "        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
    "\n",
    "        # Stage 2\n",
    "        self.stage2 = self._make_stage(2)\n",
    "        # Stage 3\n",
    "        self.stage3 = self._make_stage(3)\n",
    "        # Stage 4\n",
    "        self.stage4 = self._make_stage(4)\n",
    "\n",
    "        # Global pooling:\n",
    "        # Undefined as PyTorch's functional API can be used for on-the-fly\n",
    "        # shape inference if input size is not ImageNet's 224x224\n",
    "\n",
    "        # Fully-connected classification layer\n",
    "        num_inputs = self.stage_out_channels[-1]\n",
    "        self.fc = nn.Linear(num_inputs, self.num_classes)\n",
    "        self.init_params()\n",
    "\n",
    "\n",
    "    def init_params(self):\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                nn.init.kaiming_normal_(m.weight, mode='fan_out')\n",
    "                if m.bias is not None:\n",
    "                    nn.init.constant_(m.bias, 0)\n",
    "            elif isinstance(m, nn.BatchNorm2d):\n",
    "                nn.init.constant_(m.weight, 1)\n",
    "                nn.init.constant_(m.bias, 0)\n",
    "            elif isinstance(m, nn.Linear):\n",
    "                nn.init.normal_(m.weight, std=0.001)\n",
    "                if m.bias is not None:\n",
    "                    nn.init.constant_(m.bias, 0)\n",
    "\n",
    "\n",
    "    def _make_stage(self, stage):\n",
    "        modules = OrderedDict()\n",
    "        stage_name = \"ShuffleUnit_Stage{}\".format(stage)\n",
    "        \n",
    "        # First ShuffleUnit in the stage\n",
    "        # 1. non-grouped 1x1 convolution (i.e. pointwise convolution)\n",
    "        #   is used in Stage 2. Group convolutions used everywhere else.\n",
    "        grouped_conv = stage > 2\n",
    "        \n",
    "        # 2. concatenation unit is always used.\n",
    "        first_module = ShuffleUnit(\n",
    "            self.stage_out_channels[stage-1],\n",
    "            self.stage_out_channels[stage],\n",
    "            groups=self.groups,\n",
    "            grouped_conv=grouped_conv,\n",
    "            combine='concat'\n",
    "            )\n",
    "        modules[stage_name+\"_0\"] = first_module\n",
    "\n",
    "        # add more ShuffleUnits depending on pre-defined number of repeats\n",
    "        for i in range(self.stage_repeats[stage-2]):\n",
    "            name = stage_name + \"_{}\".format(i+1)\n",
    "            module = ShuffleUnit(\n",
    "                self.stage_out_channels[stage],\n",
    "                self.stage_out_channels[stage],\n",
    "                groups=self.groups,\n",
    "                grouped_conv=True,\n",
    "                combine='add'\n",
    "                )\n",
    "            modules[name] = module\n",
    "\n",
    "        return nn.Sequential(modules)\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.maxpool(x)\n",
    "        \n",
    "        x = self.stage2(x)\n",
    "        \n",
    "        return x\n",
    "        x = self.stage3(x)\n",
    "        x = self.stage4(x)\n",
    "\n",
    "        # global average pooling layer\n",
    "        x = F.avg_pool2d(x, x.data.size()[-2:])\n",
    "        \n",
    "        # flatten for input to fully-connected layer\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.fc(x)\n",
    "\n",
    "        return F.log_softmax(x, dim=1)\n",
    "\n"
   ],
   "id": "initial_id",
   "outputs": [],
   "execution_count": 33
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-06T09:25:44.791956Z",
     "start_time": "2024-05-06T09:25:44.760765Z"
    }
   },
   "cell_type": "code",
   "source": [
    "embed_size = 3  # Number of channels\n",
    "heads = 3\n",
    "model = ShuffleNet()\n",
    "\n",
    "image = torch.randn(3, 3, 64, 64)  # Example single image\n",
    "\n",
    "output = model(image)\n",
    "print(output.shape)"
   ],
   "id": "f9273fb7c29327ef",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 240, 8, 8])\n"
     ]
    }
   ],
   "execution_count": 34
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-06T09:25:44.839460Z",
     "start_time": "2024-05-06T09:25:44.791956Z"
    }
   },
   "cell_type": "code",
   "source": [
    "model = ShuffleUnit(in_channels=9, out_channels=18, groups=3)\n",
    "\n",
    "image = torch.randn(3, 3, 64, 64)  # Example single image\n",
    "\n",
    "output = model(image)\n",
    "print(output.shape)"
   ],
   "id": "7b855748c85fbe21",
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "out_channels must be divisible by groups",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[35], line 1\u001B[0m\n\u001B[1;32m----> 1\u001B[0m model \u001B[38;5;241m=\u001B[39m \u001B[43mShuffleUnit\u001B[49m\u001B[43m(\u001B[49m\u001B[43min_channels\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m9\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mout_channels\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m18\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mgroups\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m3\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[0;32m      3\u001B[0m image \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39mrandn(\u001B[38;5;241m3\u001B[39m, \u001B[38;5;241m3\u001B[39m, \u001B[38;5;241m64\u001B[39m, \u001B[38;5;241m64\u001B[39m)  \u001B[38;5;66;03m# Example single image\u001B[39;00m\n\u001B[0;32m      5\u001B[0m output \u001B[38;5;241m=\u001B[39m model(image)\n",
      "Cell \u001B[1;32mIn[33], line 94\u001B[0m, in \u001B[0;36mShuffleUnit.__init__\u001B[1;34m(self, in_channels, out_channels, groups, grouped_conv, combine)\u001B[0m\n\u001B[0;32m     89\u001B[0m \u001B[38;5;66;03m# Use a 1x1 grouped or non-grouped convolution to reduce input channels\u001B[39;00m\n\u001B[0;32m     90\u001B[0m \u001B[38;5;66;03m# to bottleneck channels, as in a ResNet bottleneck module.\u001B[39;00m\n\u001B[0;32m     91\u001B[0m \u001B[38;5;66;03m# NOTE: Do not use group convolution for the first conv1x1 in Stage 2.\u001B[39;00m\n\u001B[0;32m     92\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mfirst_1x1_groups \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mgroups \u001B[38;5;28;01mif\u001B[39;00m grouped_conv \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;241m1\u001B[39m\n\u001B[1;32m---> 94\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mg_conv_1x1_compress \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_make_grouped_conv1x1\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m     95\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43min_channels\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m     96\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbottleneck_channels\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m     97\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfirst_1x1_groups\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m     98\u001B[0m \u001B[43m    \u001B[49m\u001B[43mbatch_norm\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[0;32m     99\u001B[0m \u001B[43m    \u001B[49m\u001B[43mrelu\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\n\u001B[0;32m    100\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    102\u001B[0m \u001B[38;5;66;03m# 3x3 depthwise convolution followed by batch normalization\u001B[39;00m\n\u001B[0;32m    103\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdepthwise_conv3x3 \u001B[38;5;241m=\u001B[39m conv3x3(\n\u001B[0;32m    104\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mbottleneck_channels, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mbottleneck_channels,\n\u001B[0;32m    105\u001B[0m     stride\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdepthwise_stride, groups\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mbottleneck_channels)\n",
      "Cell \u001B[1;32mIn[33], line 136\u001B[0m, in \u001B[0;36mShuffleUnit._make_grouped_conv1x1\u001B[1;34m(self, in_channels, out_channels, groups, batch_norm, relu)\u001B[0m\n\u001B[0;32m    131\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_make_grouped_conv1x1\u001B[39m(\u001B[38;5;28mself\u001B[39m, in_channels, out_channels, groups,\n\u001B[0;32m    132\u001B[0m     batch_norm\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m, relu\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m):\n\u001B[0;32m    134\u001B[0m     modules \u001B[38;5;241m=\u001B[39m OrderedDict()\n\u001B[1;32m--> 136\u001B[0m     conv \u001B[38;5;241m=\u001B[39m \u001B[43mconv1x1\u001B[49m\u001B[43m(\u001B[49m\u001B[43min_channels\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mout_channels\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mgroups\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mgroups\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    137\u001B[0m     modules[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mconv1x1\u001B[39m\u001B[38;5;124m'\u001B[39m] \u001B[38;5;241m=\u001B[39m conv\n\u001B[0;32m    139\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m batch_norm:\n",
      "Cell \u001B[1;32mIn[33], line 30\u001B[0m, in \u001B[0;36mconv1x1\u001B[1;34m(in_channels, out_channels, groups)\u001B[0m\n\u001B[0;32m     25\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mconv1x1\u001B[39m(in_channels, out_channels, groups\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m1\u001B[39m):\n\u001B[0;32m     26\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\"1x1 convolution with padding\u001B[39;00m\n\u001B[0;32m     27\u001B[0m \u001B[38;5;124;03m    - Normal pointwise convolution When groups == 1\u001B[39;00m\n\u001B[0;32m     28\u001B[0m \u001B[38;5;124;03m    - Grouped pointwise convolution when groups > 1\u001B[39;00m\n\u001B[0;32m     29\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[1;32m---> 30\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mnn\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mConv2d\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m     31\u001B[0m \u001B[43m        \u001B[49m\u001B[43min_channels\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\n\u001B[0;32m     32\u001B[0m \u001B[43m        \u001B[49m\u001B[43mout_channels\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\n\u001B[0;32m     33\u001B[0m \u001B[43m        \u001B[49m\u001B[43mkernel_size\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m1\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\n\u001B[0;32m     34\u001B[0m \u001B[43m        \u001B[49m\u001B[43mgroups\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mgroups\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m     35\u001B[0m \u001B[43m        \u001B[49m\u001B[43mstride\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m1\u001B[39;49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\torch\\nn\\modules\\conv.py:447\u001B[0m, in \u001B[0;36mConv2d.__init__\u001B[1;34m(self, in_channels, out_channels, kernel_size, stride, padding, dilation, groups, bias, padding_mode, device, dtype)\u001B[0m\n\u001B[0;32m    445\u001B[0m padding_ \u001B[38;5;241m=\u001B[39m padding \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(padding, \u001B[38;5;28mstr\u001B[39m) \u001B[38;5;28;01melse\u001B[39;00m _pair(padding)\n\u001B[0;32m    446\u001B[0m dilation_ \u001B[38;5;241m=\u001B[39m _pair(dilation)\n\u001B[1;32m--> 447\u001B[0m \u001B[38;5;28msuper\u001B[39m()\u001B[38;5;241m.\u001B[39m\u001B[38;5;21m__init__\u001B[39m(\n\u001B[0;32m    448\u001B[0m     in_channels, out_channels, kernel_size_, stride_, padding_, dilation_,\n\u001B[0;32m    449\u001B[0m     \u001B[38;5;28;01mFalse\u001B[39;00m, _pair(\u001B[38;5;241m0\u001B[39m), groups, bias, padding_mode, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mfactory_kwargs)\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\torch\\nn\\modules\\conv.py:91\u001B[0m, in \u001B[0;36m_ConvNd.__init__\u001B[1;34m(self, in_channels, out_channels, kernel_size, stride, padding, dilation, transposed, output_padding, groups, bias, padding_mode, device, dtype)\u001B[0m\n\u001B[0;32m     89\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124min_channels must be divisible by groups\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[0;32m     90\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m out_channels \u001B[38;5;241m%\u001B[39m groups \u001B[38;5;241m!=\u001B[39m \u001B[38;5;241m0\u001B[39m:\n\u001B[1;32m---> 91\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mout_channels must be divisible by groups\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[0;32m     92\u001B[0m valid_padding_strings \u001B[38;5;241m=\u001B[39m {\u001B[38;5;124m'\u001B[39m\u001B[38;5;124msame\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mvalid\u001B[39m\u001B[38;5;124m'\u001B[39m}\n\u001B[0;32m     93\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(padding, \u001B[38;5;28mstr\u001B[39m):\n",
      "\u001B[1;31mValueError\u001B[0m: out_channels must be divisible by groups"
     ]
    }
   ],
   "execution_count": 35
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
